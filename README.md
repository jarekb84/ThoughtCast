# ðŸŽ™ï¸ ThoughtCast Â· Voice â†’ Text, Locally.
> Capture ideas at the speed of thought. Record, transcribe, and transform your voice into text â€” all offline, all yours.

ThoughtCast is a cross-platform desktop app that captures your spoken ideas and instantly converts them to text using local Whisper transcription.
It's designed as a high-bandwidth entry point for thought â€” speak freely, and ThoughtCast transforms your stream of consciousness into usable text for docs, PRDs, or AI workflows.

ðŸ§  Speak â†’ Transcribe â†’ Copy â†’ Create.

Everything runs locally â€” no cloud services, no external APIs â€” making it private, fast, and extensible for future integrations like LM Studio or local model post-processing.

## Current Status: Recording + Transcription MVP âœ…

ThoughtCast now includes **microphone recording with automatic Whisper transcription**!

### âœ… What Works Now
- âœ… Microphone recording with live timer
- âœ… Automatic Whisper.cpp transcription after recording
- âœ… Persistent storage of audio files and transcripts
- âœ… Session history with searchable transcript previews
- âœ… Full transcript display for each session
- âœ… Cross-platform desktop app (Windows & macOS)

### ðŸš§ Coming Soon
- Clipboard integration (auto-copy transcripts)
- Audio file import
- Search and filter transcripts
- Export sessions

## Quick Start

**Prerequisites:**
- Node.js 18+
- Rust (install from [rustup.rs](https://rustup.rs/))
- **Whisper.cpp** compiled locally ([build guide](https://github.com/ggerganov/whisper.cpp))
- **Whisper model file** downloaded (e.g., `ggml-base.bin` or `ggml-large-v3-turbo.bin`)
- Platform-specific build tools (see [BUILD_GUIDE.md](docs/BUILD_GUIDE.md))

**Setup:**

1. **Install dependencies:**
   ```bash
   npm install
   ```

2. **Create config.json:**

   Copy the example config and update paths:
   ```bash
   # On Windows, the config goes in: C:\Users\YourName\Documents\ThoughtCast\config.json
   # On macOS, the config goes in: ~/Documents/ThoughtCast/config.json
   ```

   Example `config.json`:
   ```json
   {
     "whisperPath": "C:\\Source\\whisper.cpp\\build\\bin\\Release\\whisper-cli.exe",
     "modelPath": "C:\\Source\\whisper.cpp\\models\\ggml-large-v3-turbo.bin"
   }
   ```

   See [config.example.json](config.example.json) for reference.

3. **Run the app:**
   ```bash
   npm run tauri:dev
   ```

4. **Build for production:**
   ```bash
   npm run tauri:build
   ```

For detailed setup instructions, see [BUILD_GUIDE.md](docs/BUILD_GUIDE.md).

## Documentation

- [BUILD_GUIDE.md](BUILD_GUIDE.md) - Complete build and setup instructions
- [docs/ProjectGoals.md](docs/ProjectGoals.md) - Full product requirements document

## Project Structure

```
src/                       # React frontend
  â”œâ”€â”€ components/          # UI components
  â”‚   â”œâ”€â”€ SessionList.tsx  # Sidebar with session history
  â”‚   â””â”€â”€ MainPanel.tsx    # Recording controls and transcript display
  â”œâ”€â”€ App.tsx              # Main app with state management
  â””â”€â”€ types.ts             # TypeScript interfaces

src-tauri/                 # Rust backend
  â”œâ”€â”€ src/
  â”‚   â”œâ”€â”€ lib.rs           # Tauri commands
  â”‚   â””â”€â”€ recording.rs     # Audio recording and transcription
  â”œâ”€â”€ Cargo.toml           # Rust dependencies
  â””â”€â”€ tauri.conf.json      # App configuration

Documents/ThoughtCast/     # User data directory (created on first run)
  â”œâ”€â”€ config.json          # Whisper configuration (you create this)
  â”œâ”€â”€ sessions.json        # Session index
  â”œâ”€â”€ audio/               # Recorded audio files
  â””â”€â”€ text/                # Transcript files
```

## Technology Stack

- **Frontend**: React + TypeScript + Vite
- **Backend**: Rust + Tauri
- **Audio**: cpal (cross-platform audio I/O)
- **Transcription**: Whisper.cpp (local AI model)
- **Storage**: JSON files + filesystem

## License

See [LICENSE](LICENSE)